{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e142491-3ee8-4030-a9b2-8d3504a224b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T12:51:49.573043Z",
     "iopub.status.busy": "2025-07-30T12:51:49.572518Z",
     "iopub.status.idle": "2025-07-30T12:53:36.369497Z",
     "shell.execute_reply": "2025-07-30T12:53:36.368624Z",
     "shell.execute_reply.started": "2025-07-30T12:51:49.573015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Successful\n",
      "Data successfully saved to NF_Singla_Json.json.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "available_models = [\n",
    "    \"bedrock-claude-3-sonnet-(IN)\",\n",
    "    \"gpt-4o-(US)\",\n",
    "    \"gemini-2.0-flash\",\n",
    "    \"bedrock-claude-3.5-(US)\",\n",
    "    \"gpt-4.1-(US)\",\n",
    "    \"bedrock-llama3-2-11b-(US)\",\n",
    "    \"bedrock-llama3-2-90b-(US)\",\n",
    "    \"bedrock-llama3-70b-instruct-v1-(IN)\",\n",
    "    \"bedrock-claude-3-haiku-(IN)\"\n",
    "]\n",
    "\n",
    "class LLMResponse:\n",
    "    def __init__(self, content: str):\n",
    "        self.content = content\n",
    "\n",
    "class LLM:\n",
    "    \"\"\"\n",
    "    A class that represents a language model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        authorization_token: str = \"Bearer sk-h_pNVQpyaHWjyOpwKfE5Mw\", \n",
    "        endpoint: str = \"https://llmproxy.go-yubi.in/chat/completions\", \n",
    "        temperature: float = 0, \n",
    "        model: str = \"gpt-4.1-(US)\",\n",
    "        max_tokens: Optional[int] = None\n",
    "    ):\n",
    "        if model not in available_models:\n",
    "            raise ValueError(f\"Model {model} is not available. Available models: {available_models}\")\n",
    "        self.authorization_token = authorization_token\n",
    "        self.endpoint = endpoint\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> LLMResponse:\n",
    "        \"\"\"\n",
    "        Generates a response from the language model.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": self.authorization_token,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": self.temperature\n",
    "        }\n",
    "\n",
    "        if self.max_tokens is not None:\n",
    "            data[\"max_tokens\"] = self.max_tokens\n",
    "\n",
    "        try:\n",
    "            response = requests.post(self.endpoint, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            out = response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "            return LLMResponse(out)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise Exception(f\"Error calling LLM API: {e}\")\n",
    "    \n",
    "    def invoke(self, prompt: str, system_prompt: Optional[str] = None) -> \"LLMResponse\":\n",
    "        \"\"\"\n",
    "        Invoke the LLM with the given prompt and system prompt.\n",
    "        \"\"\"\n",
    "        return self.generate(prompt, system_prompt=system_prompt)\n",
    "\n",
    "    def __or__(self, other):\n",
    "        \"\"\"\n",
    "        Allows chaining of LLM components using the | operator.\n",
    "        \"\"\"\n",
    "        return Pipeline(self, other)\n",
    "\n",
    "class JsonOutputParser:\n",
    "    \"\"\"\n",
    "    A parser that converts the output of a LLM into a Pydantic object.\n",
    "    \"\"\"\n",
    "    def __init__(self, pydantic_object):\n",
    "        self.pydantic_object = pydantic_object\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the format instructions for the Pydantic object.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            \"Output must be a valid JSON object that adheres to the following schema:\\n\" +\n",
    "            json.dumps(self.pydantic_object.model_json_schema(), indent=2)\n",
    "        )\n",
    "\n",
    "    def parse(self, text):\n",
    "        \"\"\"\n",
    "        Parses the output of a LLM into a Pydantic object.\n",
    "        \"\"\"\n",
    "        if hasattr(text, \"content\"):\n",
    "            text = text.content\n",
    "        text = text.strip()\n",
    "        if not text:\n",
    "            raise Exception(\"Warning: No JSON content received from LLM.\")\n",
    "\n",
    "        code_fence_re = r\"```[\\s]*json[\\s]*\\n(.*?)(?:```|$)\"\n",
    "        match = re.search(code_fence_re, text, re.DOTALL | re.IGNORECASE)\n",
    "        if not match:\n",
    "            code_fence_re2 = r\"```(.*?)(?:```|$)\"\n",
    "            match = re.search(code_fence_re2, text, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1).strip()\n",
    "\n",
    "        json_match = re.search(r\"({.*}|\\[.*\\])\", text, re.DOTALL)\n",
    "        if json_match:\n",
    "            text = json_match.group(1).strip()\n",
    "\n",
    "        try:\n",
    "            text = re.sub(r'(?<!\\\\)\\\\(?![\\\\/\"bfnrtu])', r'\\\\\\\\', text)\n",
    "            parsed_json = json.loads(text)\n",
    "            model_obj = self.pydantic_object.model_validate(parsed_json)\n",
    "            return model_obj.model_dump()\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Error parsing JSON output:\", e)\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        return self.parse(llm_output)\n",
    "\n",
    "class PromptTemplate:\n",
    "    \"\"\"\n",
    "    A prompt template that can be used to format a prompt for a LLM.\n",
    "    \"\"\"\n",
    "    def __init__(self, template: str, input_variables: list, partial_variables: dict = None):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "        self.partial_variables = partial_variables or {}\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Formats the prompt template with the given keyword arguments.\n",
    "        \"\"\"\n",
    "        context = self.partial_variables.copy()\n",
    "        context.update(kwargs)\n",
    "        return self.template.format(**context)\n",
    "\n",
    "    def __or__(self, other):\n",
    "        \"\"\"\n",
    "        Allows chaining of LLM components using the | operator.\n",
    "        \"\"\"\n",
    "        return Pipeline(self, other)\n",
    "\n",
    "    @classmethod\n",
    "    def from_template(cls, template: str):\n",
    "        \"\"\"\n",
    "        Creates a PromptTemplate from a template string.\n",
    "        \"\"\"\n",
    "        import string\n",
    "        input_vars = [v[1] for v in string.Formatter().parse(template) if v[1] is not None]\n",
    "        return cls(template, input_vars, {})\n",
    "\n",
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    A pipeline that chains together multiple steps for a LLM.\n",
    "    \"\"\"\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __or__(self, other):\n",
    "        \"\"\"\n",
    "        Allows chaining of LLM components using the | operator.\n",
    "        \"\"\"\n",
    "        return Pipeline(self, other)\n",
    "\n",
    "    def _has_parser(self):\n",
    "        \"\"\"\n",
    "        Recursively checks if any right step is a JsonOutputParser.\n",
    "        \"\"\"\n",
    "        node = self\n",
    "        while isinstance(node, Pipeline):\n",
    "            if isinstance(node.right, JsonOutputParser):\n",
    "                return True\n",
    "            node = node.right if isinstance(node.right, Pipeline) else None\n",
    "        return False\n",
    "\n",
    "    def _append_json_markdown_instruction(self, prompt_str):\n",
    "        \"\"\"\n",
    "        Appends a JSON markdown instruction to the prompt string if it is not already present.\n",
    "        \"\"\"\n",
    "        instruction = \"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"\n",
    "        if instruction.lower() not in prompt_str.lower():\n",
    "            prompt_str = prompt_str.rstrip() + \"\\n\\n\" + instruction\n",
    "        return prompt_str\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        \"\"\"\n",
    "        Invokes the pipeline with the given input data.\n",
    "        \"\"\"\n",
    "        parser_in_chain = self._has_parser()\n",
    "\n",
    "        if isinstance(self.left, Pipeline):\n",
    "            input_for_right = self.left.invoke(input_data)\n",
    "        elif isinstance(self.left, PromptTemplate):\n",
    "            prompt_str = self.left.format(**input_data)\n",
    "            if parser_in_chain:\n",
    "                prompt_str = self._append_json_markdown_instruction(prompt_str)\n",
    "            input_for_right = prompt_str\n",
    "        elif callable(self.left):\n",
    "            input_for_right = self.left(input_data)\n",
    "        else:\n",
    "            input_for_right = self.left\n",
    "\n",
    "        result = None\n",
    "        if isinstance(self.right, Pipeline):\n",
    "            result = self.right.invoke(input_for_right)\n",
    "        elif isinstance(self.right, LLM):\n",
    "            if isinstance(input_for_right, LLMResponse):\n",
    "                result = input_for_right\n",
    "            else:\n",
    "                result = self.right.generate(input_for_right)\n",
    "        elif isinstance(self.right, JsonOutputParser):\n",
    "            parsed = self.right.parse(input_for_right)\n",
    "            if hasattr(parsed, \"model_dump\") and callable(parsed.model_dump):\n",
    "                return parsed.model_dump()\n",
    "            else:\n",
    "                return parsed\n",
    "        elif callable(self.right):\n",
    "            result = self.right(input_for_right)\n",
    "        else:\n",
    "            result = self.right\n",
    "        return result\n",
    "\n",
    "def extract_json_from_response(text):\n",
    "    # Pattern to match JSON inside markdown fences: ```json ... ```\n",
    "    pattern = r'```[\\s]*json[\\s]*\\n(.*?)```'\n",
    "    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    # Fallback: extract the first {...} JSON object\n",
    "    match = re.search(r'(\\{.*\\})', text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    fname = \"Singla\"\n",
    "    with open(f'{fname}.txt', 'r', encoding='utf-8') as f:\n",
    "        file_content = f.read()\n",
    "    prompt_str = f\"\"\" {file_content}\n",
    "\n",
    "        1. Yearly Data Handling\n",
    "            1. For each financial year present in the document:\n",
    "                - Store the year as a key under \"financials\".\n",
    "                - Inside each year, add a \"Year\" field with the year value.\n",
    "                - Add \"unit\" field (e.g., \"INR\", \"INR_Lakh\", \"INR_Crore\") as it appears in the document.\n",
    "            2. If the document contains multiple years and any line item or variable does not have a value for one or more financial years:\n",
    "                - Explicitly set its value as null for that year.\n",
    "                - Do not infer, copy, or generate missing values.\n",
    "                - Only assign values if they are explicitly stated under the correct financial year.\n",
    "                - Do not use values from other years as placeholders (no forward-fill or backfill logic).\n",
    "            3. Previous year data may appear in the following formats:\n",
    "                - A dedicated \"(Previous Year)\" row at the bottom of tables.\n",
    "                - Column labels with year references like “2022” or “as on 31.03.2022”.\n",
    "                - Footnote-style blocks labeled “(Previous Year)” or “Note: Previous Year data”.\n",
    "            4. These formats **must be parsed and mapped** as valid data for the correct financial year, even if presented below current year values.\n",
    "            5. Values labeled as “Grand Total”, “Net Block Written Down Value as on 31.03.2022”, or other summary rows must also be extracted and assigned to the correct year.\n",
    "            6. Do not assign any value to a year unless it is explicitly stated under that year or labeled as “Previous Year”.\n",
    "            7. If values appear in tables or blocks where \"Previous Year\" is shown as a summary row (e.g., under Total or Grand Total), those values must be parsed correctly and mapped under that year.\n",
    "            8. If a line item appears for a year but its value is blank or missing, store it as null.\n",
    "            9. Never copy a value from one year to another (e.g., do not use the \"Opening Balance\" of 2023 as the \"Closing Balance\" for 2022 unless explicitly stated in the document).\n",
    "            10. When reading line-by-line notes or block entries (e.g., Notes 3 or 11), do not skip \"(Previous Year)\" rows or summary totals; these must be processed and mapped just like tabular entries.\n",
    "\n",
    "        2. Data Organization per Year\n",
    "            For each financial year, structure the output in this order:\n",
    "                1. \"Year\": Financial year (e.g., \"2023\")\n",
    "                2. \"unit\": Unit of measure (e.g., \"INR_Lakh\")\n",
    "                3. \"Balance sheet\": Extract all Balance Sheet data excluding notes.\n",
    "                4. \"Balance sheet notes\": Notes related to Balance Sheet (see Notes Handling below).\n",
    "                5. \"Profit loss\": Extract all Profit and Loss account data excluding notes.\n",
    "                6. \"Profit loss notes\": Notes related to Profit and Loss.\n",
    "                7. \"Trading\": Extract Trading account data (if present).\n",
    "                8. \"Trading notes\": Notes related to Trading account.\n",
    "\n",
    "       3. Data Mapping & Hierarchy Rules\n",
    "            Use exact headings and subheadings from the document as keys.\n",
    "            Extract hierarchies accurately (e.g., “Tangible Assets” > “Block A” > sub-entries).\n",
    "            If subtotals are present, extract them under the key \"Total [Subheading]\".\n",
    "            For deduction or addition parts in Balance Sheet, include them under correct sections. Include Total Additions and Total Deductions if present.\n",
    "            Continue this nesting for any further hierarchical levels if present.\n",
    "\n",
    "        4. Special Line Items Handling\n",
    "            Extract Gross Profit C/d and Gross Profit B/d only if explicitly present.\n",
    "                If both Trading and Profit & Loss are on the same page, do not auto-balance them — extract the values as given.\n",
    "            In Trading and Profit & Loss, extract:\n",
    "                total debit\n",
    "                total credit\n",
    "                Store these totals under the respective section (Trading or Profit loss).\n",
    "        \n",
    "        5. Notes Extraction\n",
    "            For each notes section (Balance Sheet Notes, Profit Loss Notes, Trading Notes):\n",
    "            1. Extract:\n",
    "                Note number or Note title\n",
    "                Balance sheet item/Profit Loss item/Trading item (line item the note relates to)\n",
    "                Classification (valid values: equity, current_assets, non_current_assets, current_liabilities, non_current_liabilities, assets_miscellaneous, liabilities_miscellaneous)\n",
    "                Notes: Actual data under the note\n",
    "            2. If the note contains addition sections split by dates (e.g., “UP TO 30.09.2023” and “AFTER 01.10.2023”), extract both sections under the correct year with clear keys.\n",
    "            3. Preserve all nested subheadings and sub-structures inside notes exactly as they appear in the document.\n",
    "            4. If no notes are present for a section, store an empty array.\n",
    "        \n",
    "        6. Handling Schedules/Notes and References\n",
    "            If a main statement (Balance Sheet, Profit & Loss, or Trading) references a schedule or note (e.g., “Note 1”, “Schedule A”), extract the note/schedule data under the corresponding notes section:\n",
    "                \"Balance sheet notes\"\n",
    "                \"Profit loss notes\"\n",
    "                \"Trading notes\"\n",
    "            Extra Notes\n",
    "                Extract any remaining notes not referenced by Balance Sheet, Profit & Loss, or Trading statements under the key: \"Extra notes\" (only once).\n",
    "                Ensure no duplication of notes across different sections.\n",
    "        \n",
    "        General Rules\n",
    "            Preserve original numeric formatting (do not convert numbers to strings).\n",
    "            Do not infer or generate values — store only what is present.\n",
    "            If any data (line-item or subtotal) is missing in the document for any year, set its value as null.\n",
    "            Use exact structure, headings, and labels as in the document.\n",
    "            Give both Total of line items which are already present in the document along with the line items,don't miss out anything.'\n",
    "            Return only a valid JSON object (no markdown, no explanations, no extra text).\n",
    "        \n",
    "     Here is the document to process: \"\"\"\n",
    "\n",
    "    # Simulated: Replace with your own LLM object and inference method\n",
    "    llm = LLM()\n",
    "    output = llm.generate(prompt_str)\n",
    "    print('Extraction Successful')\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # Converting to Json file\n",
    "    # --------------------------------------------------------------\n",
    "    response_str = output.content\n",
    "\n",
    "    # Extract the JSON text\n",
    "    json_text = extract_json_from_response(response_str)\n",
    "    if json_text:\n",
    "        try:\n",
    "            # Parse the JSON to a dictionary\n",
    "            data = json.loads(json_text)\n",
    "            # Save to a file\n",
    "            with open(f'NF_{fname}_Json.json', 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "            print(f\"Data successfully saved to NF_{fname}_Json.json.\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Could not find a valid JSON in the response.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c8f33-a330-4f22-a5ee-eca8e2ec0d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
